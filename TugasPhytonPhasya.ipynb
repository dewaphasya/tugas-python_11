{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "mount_file_id": "1jhI83HY8fpX8q2xadHHcbOQgv770ccVa",
      "authorship_tag": "ABX9TyNTQVTmNWwD1EN7Mj5MW/Cb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dewaphasya/tugas-python_11/blob/main/TugasPhytonPhasya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj1PROrREhxD"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H215ikbNVVZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b875c48-b1a3-415c-ebd1-2adfe2b6d164"
      },
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7VB1d4wVdov",
        "outputId": "62b4b27f-5956-455a-ab53-2b686d63e662"
      },
      "source": [
        "ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Copy of Copy of scenes_nn_4 layers.ipynb'   daun.jpg          Untitled1.ipynb\n",
            " \u001b[0m\u001b[01;36mdataset\u001b[0m@                                    Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IGm26ZzVGBs"
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-5PXYTsVGBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07cbb1c-ec54-4c4d-957f-59bec2aa9906"
      },
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths1 = paths.list_images(\"GMB_01\")\n",
        "imagePaths2 = paths.list_images(\"GMB_03\")\n",
        "imagePaths3 = paths.list_images(\"GMB_07\")\n",
        "imagePaths4 = paths.list_images(\"GMB_08\")\n",
        "imagePaths5 = paths.list_images(\"GMB_09\")\n",
        "data = []\n",
        "labels = []"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q-KXSsGVGB0"
      },
      "source": [
        "for imagePath in imagePaths1:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "for imagePath in imagePaths2:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "for imagePath in imagePaths3:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "for imagePath in imagePaths4:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "for imagePath in imagePaths5:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzbolh88VGB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197ed68c-8350-406c-e7a4-f4513f1a10fd"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twd1IeuKVGB5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "10208f5d-84b0-43be-e3f3-5f2ec906ba7c"
      },
      "source": [
        "# encode the labels, converting them from strings to integers\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e4968e9aa819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# encode the labels, converting them from strings to integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \"\"\"\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    427\u001b[0m                              \"label binarization\")\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y has 0 samples: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y has 0 samples: []"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FPCyIqcVGB7"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktZ5hNYwVGB9"
      },
      "source": [
        "# perform a training and testing split, using 75% of the data for\n",
        "# training and 25% for evaluation\n",
        "(trainX, testX, trainY, testY) = train_test_split(np.array(data),\tnp.array(labels), test_size=0.25, shuffle=True)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSxR7GLQvrUP"
      },
      "source": [
        "from keras.layers import Convolution2D, MaxPool2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Convolution2D(8, (3,3), activation='relu', input_shape=(168,168,3)))\n",
        "model1.add(MaxPool2D(2,2))\n",
        "model1.add(Convolution2D(16, (3,3), activation='relu'))\n",
        "model1.add(MaxPool2D(2,2))\n",
        "#fully connected layer\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(100, activation='relu'))\n",
        "model1.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggcSdj_aVGCB",
        "scrolled": true
      },
      "source": [
        "# train the model using the Adam optimizer\n",
        "print(\"[INFO] training network...\")\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 50)\n",
        "model1.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bbMakb0w-XZ"
      },
      "source": [
        "H = model1.fit(trainX, trainY, validation_data=(testX, testY), epochs=30, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98_oXi-lcgux"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(H.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(H.history['accuracy'])\n",
        "plt.plot(H.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPAZkmBJVGCD"
      },
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model1.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=lb.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQcNvdOeAQTt"
      },
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMdUR2iEAX_i"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uBcj8x8iwTw"
      },
      "source": [
        "model1.save('nnmodel_scene')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOwJT2jLVGCN"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "image1='daun.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkM68K4GVGCP"
      },
      "source": [
        "img_array = cv2.imread(image1)\n",
        "print(type(img_array))\n",
        "plt.imshow(img_array)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZkNY8LWVGCR"
      },
      "source": [
        "image_testing = Image.open('daun.jpg')\n",
        "image_testing = np.array(image_testing.resize((168, 168))) / 255.0\n",
        "image_testing.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL66nfOcVGCT"
      },
      "source": [
        "image_testing = np.expand_dims(image_testing, axis=0)\n",
        "print(image_testing.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTy9yP1AVGCV"
      },
      "source": [
        "output = model1.predict(image_testing, 1)\n",
        "print(output)\n",
        "print(lb.classes_[output.argmax(axis=1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjJy6fB1F9ib"
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpZdX5SPF9ic"
      },
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths1 = paths.list_images(\"GMB_01\")\n",
        "imagePaths2 = paths.list_images(\"GMB_03\")\n",
        "imagePaths3 = paths.list_images(\"GMB_07\")\n",
        "imagePaths4 = paths.list_images(\"GMB_08\")\n",
        "imagePaths5 = paths.list_images(\"GMB_09\")\n",
        "data = []\n",
        "labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3095mQdF9ie"
      },
      "source": [
        "for imagePath in imagePaths1:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "for imagePath in imagePaths2:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "for imagePath in imagePaths3:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "for imagePath in imagePaths4:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "for imagePath in imagePaths5:\n",
        "  image = Image.open(imagePath)\n",
        "  image = np.array(image.resize((168, 168))) / 255.0 #normalisasi\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUkRxRGkF9ie"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0TQPdNzF9ie"
      },
      "source": [
        "# encode the labels, converting them from strings to integers\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhGgB5ycF9ie"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGqtVAZCF9ie"
      },
      "source": [
        "# perform a training and testing split, using 75% of the data for\n",
        "# training and 25% for evaluation\n",
        "(trainX, testX, trainY, testY) = train_test_split(np.array(data),\tnp.array(labels), test_size=0.25, shuffle=True)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q12Q6h9mF9ie"
      },
      "source": [
        "from keras.layers import Convolution2D, MaxPool2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Convolution2D(8, (3,3), activation='relu', input_shape=(168,168,3)))\n",
        "model1.add(MaxPool2D(2,2))\n",
        "model1.add(Convolution2D(16, (3,3), activation='relu'))\n",
        "model1.add(MaxPool2D(2,2))\n",
        "#fully connected layer\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(100, activation='relu'))\n",
        "model1.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MJqRN8KuF9ie"
      },
      "source": [
        "# train the model using the Adam optimizer\n",
        "print(\"[INFO] training network...\")\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 50)\n",
        "model1.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtqZBNdQF9if"
      },
      "source": [
        "H = model1.fit(trainX, trainY, validation_data=(testX, testY), epochs=30, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqHWdEz0F9if"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(H.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(H.history['accuracy'])\n",
        "plt.plot(H.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t9ajPm5F9if"
      },
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model1.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=lb.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TuY9-2FF9ig"
      },
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqxChEg-F9ig"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il8CuITEF9ig"
      },
      "source": [
        "model1.save('nnmodel_scene')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0GXPhyyF9ig"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "image1='daun.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CtayXLdF9ig"
      },
      "source": [
        "img_array = cv2.imread(image1)\n",
        "print(type(img_array))\n",
        "plt.imshow(img_array)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9P3UXdmF9ig"
      },
      "source": [
        "image_testing = Image.open('daun.jpg')\n",
        "image_testing = np.array(image_testing.resize((168, 168))) / 255.0\n",
        "image_testing.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwxqSHzeF9ig"
      },
      "source": [
        "image_testing = np.expand_dims(image_testing, axis=0)\n",
        "print(image_testing.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BopIKWTTF9ig"
      },
      "source": [
        "output = model1.predict(image_testing, 1)\n",
        "print(output)\n",
        "print(lb.classes_[output.argmax(axis=1)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}